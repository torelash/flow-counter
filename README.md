# ðŸ›£ï¸ Flow-Counter: Vehicle & People Counter using YOLOv8 + SORT

> Count vehicles and people in videos using deep learning and object tracking.

---

## âš¡ Quick Start

### 1ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
# or individually:
pip install ultralytics opencv-python cvzone filterpy
apt install ffmpeg -y   # for Colab re-encoding
```

### 2ï¸âƒ£ Run baseline (stable)
```bash
python src/main.py
```

### 3ï¸âƒ£ Run experimental (auto lane detection)
```bash
python src/main_two.py
```

**Output files:**
```
result_dual.mp4
result_single.mp4
```

---

## ðŸŒ Overview
Flow-Counter combines **YOLOv8** object detection and **SORT** tracking to automatically **count vehicles and pedestrians** in traffic videos.  
It detects whether a scene is **single-lane** or **dual-lane**, tracks moving objects, and produces an **annotated MP4 video** showing total and directional counts.

---

## ðŸ§  How It Works
```
VIDEO â†’ YOLO Detection â†’ SORT Tracking â†’ Line Crossing Check â†’ Count Update â†’ Annotated Output
```
1. **YOLOv8** detects objects (cars, trucks, buses, motorbikes, people).  
2. **SORT** tracks each detected object across frames using Kalman filtering.  
3. When a tracked object crosses a â€œcounting gateâ€ (a red line), itâ€™s counted once per direction.  
4. The system overlays all bounding boxes, lines, and counts on the output video.

---

## ðŸš€ Key Features
- Real-time object detection (YOLOv8)  
- Object tracking with SORT  
- Auto scene detection (single vs dual lane)  
- Directional flow counting  
- Annotated MP4 output  
- Manual gate tuning through fractional coordinates  
- Optional ROI masking for focus regions  

---

## ðŸ“ Project Structure
```bash
flow-counter/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py          # âœ… Baseline (stable) YOLO+SORT counter
â”‚   â”œâ”€â”€ main_two.py      # ðŸ§ª Experimental version with auto lane detection
â”‚   â””â”€â”€ trackers/
â”‚       â””â”€â”€ sort.py      # SORT tracker (Kalman-based)
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ traffic_cam.mp4  # Example input video
â”‚   â”œâ”€â”€ mask.png         # Optional ROI mask
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ result_dual.mp4      # Example annotated output
```

---

## âš™ï¸ Configuration
Edit parameters directly in `src/main.py` or `src/main_two.py`.

| Parameter | Description |
|------------|-------------|
| `MODEL_PATH` | YOLO weights file (`yolov8l.pt`, `yolov8n.pt`, etc.) |
| `VIDEO_PATH` | Input video |
| `AUTO_MODE` | Enable auto lane detection (only in `main_two.py`) |
| `FORCE_MODE` | Manually override mode (â€œsingleâ€ or â€œdualâ€) |
| `DUAL_*_FRAC` | Gate line positions for dual-lane setup |
| `SINGLE_*_FRAC` | Mid-line position for single-lane setup |
| `GATE_NUDGE` | Fractional adjustments to fine-tune gate placement |
| `CONF_MIN`, `IOU_NMS` | YOLO detection thresholds |

---

## â–¶ï¸ Usage

### Baseline (Stable)
```bash
python src/main.py
```
This version uses fixed line coordinates. Reliable for dual-lane traffic videos.

### Experimental (Auto Mode)
```bash
python src/main_two.py
```
This version automatically determines whether the video is single or dual-lane, then adjusts gate positions.

---

## ðŸ“Š Output Visualization
| Element | Meaning |
|--------|---------|
| ðŸ”´ Red lines | Counting gates |
| ðŸŸ© Green flashes | Object successfully counted |
| ðŸŸª Magenta boxes | Active tracked objects |
| ðŸ§¾ On-screen text | Total / Up / Down counts |

---

## ðŸ› ï¸ Prerequisites
Youâ€™ll need:
- Python 3.8+
- OpenCV
- Ultralytics YOLOv8
- cvzone
- filterpy

Install all at once:
```bash
pip install ultralytics opencv-python cvzone filterpy
```

If using Google Colab:
```bash
apt install ffmpeg -y
```

---

## âš ï¸ Notes & Limitations
- **Auto-mode detection:** Works best for clear overhead or angled scenes; may misclassify on short or diagonal clips.  
- **Counting sensitivity:** Objects may be tracked but not counted if they donâ€™t fully cross a gate or lose ID due to blur/occlusion.  
- **Gate calibration:** Line positions are static but tunable.  
- **Frame rate sensitivity:** Low-FPS or motion blur can cause missed counts.  
- **Ethical limitation:** This project does not analyze demographics, race, or facial attributes â€” only movement and object type.

---

## ðŸ“ˆ Future Improvements
- Optical-flowâ€“based adaptive gate placement (Farneback / RAFT)  
- Improved tracking for temporary occlusions  
- Streamlit web interface for uploads and analytics  
- Animated overlays (icons instead of boxes)  
- Statistical summaries: flow per minute, lane occupancy, etc.

---

## ðŸ™Œ Acknowledgments
- **Ultralytics YOLOv8** â€” object detection  
- **Alex Bewleyâ€™s SORT** â€” real-time tracking  
- **OpenCV & cvzone** â€” visualization tools  

---

## ðŸ§© Version Guide
| File | Role | Stability |
|------|------|-----------|
| `main.py` | Baseline version (manual gate setup, tested) | âœ… Stable |
| `main_two.py` | Auto scene detection & adaptive gates | ðŸ§ª Experimental |

---

## ðŸ“¸ Example Output (Placeholder)
Add your result screenshot here:
```bash
![Example Output](assets/example_frame.jpg)
```

---

**Developed by Toorese Lasebikan, 2025**

---

### requirements.txt
```bash
ultralytics>=8.0.0
opencv-python
cvzone
filterpy
```




